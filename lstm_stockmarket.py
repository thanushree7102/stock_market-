# -*- coding: utf-8 -*-
"""LSTM_StockMarket.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19xPffOGEJmiizZ7d2vGxqGBOqio__BIz
"""

from google.colab import files
files.upload()

!mv "kaggle (1).json" kaggle.json

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json


!pip install -q kaggle

!kaggle datasets download -d gratefuldata/intraday-stock-data-1-min-sp-500-200821


!unzip -q intraday-stock-data-1-min-sp-500-200821.zip

import pandas as pd
import numpy as np
data_path = "/content/1_min_SPY_2008-2021.csv"
df = pd.read_csv(data_path, parse_dates=['date'], index_col=0)
print("Data loaded. Number of rows:", len(df))
df.head()

dup_count = df.duplicated().sum()
print(f"Duplicate rows before drop: {dup_count}")
if dup_count > 0:
    df = df[~df.duplicated()]
    print("Duplicates dropped.")


print("Null values per column:\n", df.isnull().sum())


numeric_cols = ['open','high','low','close','volume','barCount','average']
for col in numeric_cols:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')

df.dropna(inplace=True)
print("Data types after conversion:\n", df.dtypes)

symbol_col = None
if 'symbol' in df.columns:
    symbol_col = 'symbol'
elif 'ticker' in df.columns:
    symbol_col = 'ticker'

if symbol_col:
    top_symbol = df.groupby(symbol_col)['volume'].sum().idxmax()
    df = df[df[symbol_col] == top_symbol]
    print(f"Selected ticker: {top_symbol}")
else:
    top_symbol = "SPY"
    print("No symbol column found; assuming single-ticker data (SPY).")


print("Date range:", df.index.min(), "to", df.index.max())

print(df.info())

df.describe().T

# Commented out IPython magic to ensure Python compatibility.
!pip install seaborn
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

sns.set_theme(style="darkgrid")

# Plot closing price over time
plt.figure(figsize=(12,4))
plt.plot(df.index, df['close'], color='blue', linewidth=0.5)
plt.title('SPY Close Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price (USD)')
plt.tight_layout()
plt.show()

# Plot trading volume over time
plt.figure(figsize=(12,4))
plt.plot(df.index, df['volume'], color='orange', linewidth=0.5)
plt.title('SPY Trading Volume Over Time')
plt.xlabel('Date')
plt.ylabel('Volume')
plt.tight_layout()
plt.show()

# Compute returns
df['return'] = df['close'].pct_change() * 100  # percentage returns
returns = df['return'].dropna()

# Histogram + KDE of returns
plt.figure(figsize=(8,4))
sns.histplot(returns, bins=200, kde=True, color='skyblue')
plt.title('Histogram and KDE of 1-Minute Returns')
plt.xlabel('Return (%)')
plt.xlim(-1, 1)
plt.tight_layout()
plt.show()

# Histogram + KDE of volume (log scale)
plt.figure(figsize=(8,4))
sns.histplot(df['volume'], bins=200, kde=True, color='salmon')
plt.xlim(0, df['volume'].quantile(0.99))  # truncate for visibility
plt.title('Histogram and KDE of Trading Volume (1-min)')
plt.xlabel('Volume')
plt.tight_layout()
plt.show()

# Boxplot of returns
plt.figure(figsize=(6,4))
sns.boxplot(x=returns, color='lightgreen')
plt.title('Boxplot of 1-Minute Returns')
plt.xlabel('Return (%)')
plt.tight_layout()
plt.show()

# Boxplot of volume
plt.figure(figsize=(6,4))
sns.boxplot(x=np.log1p(df['volume']), color='tan')  # log(1+volume) for scale
plt.title('Boxplot of Log(Volume + 1)')
plt.xlabel('Log(Volume + 1)')
plt.tight_layout()
plt.show()

# Sample data for pairplot (for speed and clarity)
sample_df = df[['open','high','low','close','volume','barCount','average']].dropna().sample(2000, random_state=0)
sns.pairplot(sample_df, diag_kind='kde', plot_kws={'alpha':0.5, 's':10})
plt.suptitle('Pairplot of Price and Volume Features (Sample)', y=1.02)
plt.show()

# Correlation matrix heatmap
corr = df[['open','high','low','close','volume','barCount','average']].corr()
plt.figure(figsize=(6,5))
sns.heatmap(corr, annot=True, fmt=".2f", cmap='coolwarm', square=True)
plt.title('Correlation Matrix')
plt.tight_layout()
plt.show()

# Ensure datetime index is correct
df.index = pd.to_datetime(df.index)

# Extract hour from timestamp
df['hour'] = df.index.hour

# Grouping
hourly_vol = df.groupby('hour')['volume'].mean()
hourly_close = df.groupby('hour')['close'].mean()

# Bar plot: average volume
plt.figure(figsize=(8,4))
hourly_vol.plot(kind='bar', color='steelblue')
plt.title('Average 1-min Trading Volume by Hour of Day')
plt.xlabel('Hour of Day')
plt.ylabel('Mean Volume')
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

# Line plot: average closing price
plt.figure(figsize=(8,4))
plt.plot(hourly_close.index, hourly_close.values, marker='o', color='green')
plt.title('Average SPY Close Price by Hour of Day')
plt.xlabel('Hour of Day')
plt.ylabel('Mean Close Price (USD)')
plt.xticks(range(hourly_close.index.min(), hourly_close.index.max()+1))
plt.grid(True)
plt.tight_layout()
plt.show()

# boxplot to visualize outliers
import seaborn as sns
import matplotlib.pyplot as plt


columns = ['open', 'high', 'low', 'close', 'volume', 'average']

plt.figure(figsize=(14, 6))
df[columns].plot(kind='box', subplots=True, layout=(2, 3), figsize=(15, 8), sharex=False, sharey=False)
plt.suptitle("Boxplots Before Outlier Handling")
plt.tight_layout()
plt.show()

def handle_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR


    df[column] = df[column].clip(lower=lower, upper=upper)

    return df

for col in ['open', 'high', 'low', 'close', 'volume', 'average']:
    df = handle_outliers_iqr(df, col)

# boxplot after outlier handling
plt.figure(figsize=(14, 6))
df[columns].plot(kind='box', subplots=True, layout=(2, 3), figsize=(15, 8), sharex=False, sharey=False)
plt.suptitle("Boxplots After Outlier Handling")
plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

data = df[['close']].values

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# Create sequences for LSTM
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(seq_length, len(data)):
        X.append(data[i - seq_length:i, 0])
        y.append(data[i, 0])
    return np.array(X), np.array(y)

sequence_length = 60
X, y = create_sequences(scaled_data, sequence_length)

# Reshape for LSTM input
X = np.reshape(X, (X.shape[0], X.shape[1], 1))

# Split into training and testing sets
train_size = int(len(X) * 0.8)
X_train, y_train = X[:train_size], y[:train_size]
X_test, y_test = X[train_size:], y[train_size:]

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import tensorflow as tf

# Check GPU
print("GPU Available:", tf.config.list_physical_devices('GPU'))

# Build the LSTM model
model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),
    Dropout(0.2),
    LSTM(50, return_sequences=False),
    Dropout(0.2),
    Dense(25),
    Dense(1)
])

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')
model.summary()

# Train the model
history = model.fit(X_train, y_train, batch_size=32, epochs=25, validation_data=(X_test, y_test))

# Make predictions
predictions = model.predict(X_test)
predictions = scaler.inverse_transform(predictions.reshape(-1, 1))

# Inverse transform the actual values
actual = scaler.inverse_transform(y_test.reshape(-1, 1))

# Plot predictions vs actual
plt.figure(figsize=(14,6))
plt.plot(actual, color='blue', label='Actual Stock Price')
plt.plot(predictions, color='red', label='Predicted Stock Price')
plt.title('Stock Price Prediction vs Actual')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

mse = mean_squared_error(actual, predictions)
mae = mean_absolute_error(actual, predictions)
r2 = r2_score(actual, predictions)

print(f"Mean Squared Error: {mse}")
print(f"Mean Absolute Error: {mae}")
print(f"R2 Score: {r2}")

from keras.models import load_model

model.save("lstm_stock_model.keras")

#Predict Future Prices (Forecasting)
last_sequence = scaled_data[-sequence_length:]  # last 60 points
last_sequence = np.expand_dims(last_sequence, axis=0)
next_price_scaled = model.predict(last_sequence)
next_price = scaler.inverse_transform([[next_price_scaled[0][0]] + [0]*7])[0][0]
print(f"Next predicted price: {next_price}")